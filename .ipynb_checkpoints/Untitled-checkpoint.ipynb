{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4674d82-f376-4b3d-9879-ae6d4e1f3104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3119310308.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    please correct this code\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "please correct this code\n",
    "\n",
    "please correct this code\n",
    "mktg_df\n",
    "responded_yes_df = mktg_df[mktg_df['response'] == 'Yes']\n",
    "print(\"The average total_claim_amount is: \")\n",
    "print(mktg_df.total_claim_amount.mean())\n",
    "print(\"The average total_claim_amount for customers who have responded yes is: \")\n",
    "print(responded_yes_df.total_claim_amount.mean())\n",
    "print()\n",
    "#responded_yes_df = mktg_df[mktg_df['response'] == 'Yes']\n",
    "avrg_policy_claims = responded_yes_df.groupby(['policy_type'])['total_claim_amount'].mean().reset_index()\n",
    "avrg_gender_claims = responded_yes_df.groupby(['gender'])['total_claim_amount'].mean().reset_index()\n",
    "avrg_claims = responded_yes_df.groupby(['policy_type', 'gender'])['total_claim_amount'].mean().reset_index()\n",
    "print(\"The average total_claim_amount by each policy type is: \")\n",
    "print(avrg_policy_claims)\n",
    "print()\n",
    "print(\"The average total_claim_amount by each policy type is: \")\n",
    "print(avrg_gender_claims)\n",
    "print()\n",
    "print(\"The average total_claim_amount by each policy type and gender is: \")\n",
    "print(avrg_claims)\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[125], line 5\n",
    "      3 print(mktg_df.total_claim_amount.mean())\n",
    "      4 print(\"The average total_claim_amount for customers who have responded yes is: \")\n",
    "----> 5 print(responded_yes_df.total_claim_amount.mean())\n",
    "      6 print()\n",
    "      7 responded_yes_df = mktg_df[mktg_df['response'] == 'Yes']\n",
    "\n",
    "NameError: name 'responded_yes_df' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eab09d-d4d3-49a5-8abe-4eaf1731705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "please correct this code\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mktg_df= pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#clean columns names: lowercase, delete 0 in unnamed, employment status  space, change spaces for_, empty column?, \n",
    "# duplicates, nulls, formatting string and numbers and dates (map, apply)\n",
    "#with function (function that put column names in lowercase, replaces whithe espaces by _ and change  st to state\n",
    "\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    df = df.rename(columns={str('employmentstatus'): 'employment_status'})\n",
    "    df = df.rename(columns={str('unnamed:_0'): 'unnamed'})\n",
    "    return df    \n",
    "    \n",
    "    #return df\n",
    "\n",
    "mktg_df= clean_column_names(mktg_df)\n",
    "mktg_df.head()\n",
    "\n",
    "#The marketing team wants to analyze the number of policies sold by state and month. Present the data in a table where the months are arranged as columns and the states are arranged as rows.\n",
    "\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "mktg_df['effective_to_date'] = pd.to_datetime(mktg_df['effective_to_date'], format='%m/%d/%y')\n",
    "\n",
    "# Create a new column with the month\n",
    "mktg_df['month'] = mktg_df['effective_to_date'].dt.strftime('%B')\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "pivot_df = mktg_df.pivot(index='state', columns='month', values='states')\n",
    "mktg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d0b29-388a-4266-8d28-2b81e9be6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "customer_df['effective_to_date'] = pd.to_datetime(customer_df['effective_to_date'])\n",
    "mktg_df['month'] = mktg_df['effective_to_date'].dt.strftime('%B')\n",
    "\n",
    "pivot_df = customer_df.pivot_table(index='month', columns='policy_type', values=\"total_claim_amount\", aggfunc='count', fill_value=0)\n",
    "\n",
    "print(pivot_df.head())\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "Cell In[179], line 3\n",
    "      1 # Convert the 'date' column to datetime format\n",
    "      2 customer_df['effective_to_date'] = pd.to_datetime(customer_df['effective_to_date'])\n",
    "----> 3 mktg_df['month'] = mktg_df['effective_to_date'].dt.strftime('%B')\n",
    "      5 pivot_df = customer_df.pivot_table(index='month', columns='policy_type', values=\"total_claim_amount\", aggfunc='count', fill_value=0)\n",
    "      7 print(pivot_df.head())\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6204, in NDFrame.__getattr__(self, name)\n",
    "   6197 if (\n",
    "   6198     name not in self._internal_names_set\n",
    "   6199     and name not in self._metadata\n",
    "   6200     and name not in self._accessors\n",
    "   6201     and self._info_axis._can_hold_identifiers_and_holds_name(name)\n",
    "   6202 ):\n",
    "   6203     return self[name]\n",
    "-> 6204 return object.__getattribute__(self, name)\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls)\n",
    "    221 if obj is None:\n",
    "    222     # we're accessing the attribute of the class, i.e., Dataset.geo\n",
    "    223     return self._accessor\n",
    "--> 224 accessor_obj = self._accessor(obj)\n",
    "    225 # Replace the property with the accessor object. Inspired by:\n",
    "    226 # https://www.pydanny.com/cached-property.html\n",
    "    227 # We need to use object.__setattr__ because we overwrite __setattr__ on\n",
    "    228 # NDFrame\n",
    "    229 object.__setattr__(obj, self._name, accessor_obj)\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/accessors.py:608, in CombinedDatetimelikeProperties.__new__(cls, data)\n",
    "    605 elif isinstance(data.dtype, PeriodDtype):\n",
    "    606     return PeriodProperties(data, orig)\n",
    "--> 608 raise AttributeError(\"Can only use .dt accessor with datetimelike values\")\n",
    "\n",
    "AttributeError: Can only use .dt accessor with datetimelike values\n",
    "1\n",
    "â€‹\n",
    "\n",
    "the format of the data is \n",
    "array(['2011-02-18', '2011-01-18', '2011-02-10', '2011-01-11',\n",
    "       '2011-01-17', '2011-02-14', '2011-02-24', '2011-01-19',\n",
    "       '2011-01-04', '2011-01-02', '2011-02-07', '2011-01-31',\n",
    "       '2011-01-26', '2011-02-28', '2011-01-16', '2011-02-26',\n",
    "       '2011-02-23', '2011-01-15', '2011-02-02', '2011-02-15',\n",
    "       '2011-01-24', '2011-02-21', '2011-02-22', '2011-01-07',\n",
    "       '2011-01-28', '2011-02-08', '2011-02-12', '2011-02-20',\n",
    "       '2011-01-05', '2011-02-19', '2011-01-03', '2011-02-03',\n",
    "       '2011-01-22', '2011-01-23', '2011-02-05', '2011-02-13',\n",
    "       '2011-01-25', '2011-02-16', '2011-02-01', '2011-01-27',\n",
    "       '2011-01-12', '2011-01-20', '2011-02-06', '2011-02-11',\n",
    "       '2011-01-21', '2011-01-29', '2011-01-09', '2011-02-09',\n",
    "       '2011-02-27', '2011-01-01', '2011-02-17', '2011-02-25',\n",
    "       '2011-01-13', '2011-01-06', '2011-02-04', '2011-01-14',\n",
    "       '2011-01-10', '2011-01-08', '2011-01-30'], dtype=object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850c137-0870-4c3b-865f-e81da5baeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format\n",
    "customer_df['effective_to_date'] = pd.to_datetime(mktg_df['effective_to_date'], format='%y-%m-%d')\n",
    "\n",
    "# Create a new column with the month\n",
    "customer_df['month'] = customer_df['effective_to_date'].dt.strftime('%B')\n",
    "\n",
    "\n",
    "pivot_df = customer_df.pivot_table(index='month', columns='policy_type', values=\"total_claim_amount\", aggfunc='count', fill_value=0)\n",
    "\n",
    "print(pivot_df.head())\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[171], line 2\n",
    "      1 # Convert the 'date' column to datetime format\n",
    "----> 2 customer_df['effective_to_date'] = pd.to_datetime(mktg_df['effective_to_date'], format='%y-%m-%d')\n",
    "      4 # Create a new column with the month\n",
    "      5 customer_df['month'] = customer_df['effective_to_date'].dt.strftime('%B')\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1108, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\n",
    "   1106             result = arg.tz_localize(\"utc\")\n",
    "   1107 elif isinstance(arg, ABCSeries):\n",
    "-> 1108     cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
    "   1109     if not cache_array.empty:\n",
    "   1110         result = arg.map(cache_array)\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:254, in _maybe_cache(arg, format, cache, convert_listlike)\n",
    "    252 unique_dates = unique(arg)\n",
    "    253 if len(unique_dates) < len(arg):\n",
    "--> 254     cache_dates = convert_listlike(unique_dates, format)\n",
    "    255     # GH#45319\n",
    "    256     try:\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\n",
    "    486 # `format` could be inferred, or user didn't ask for mixed-format parsing.\n",
    "    487 if format is not None and format != \"mixed\":\n",
    "--> 488     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n",
    "    490 result, tz_parsed = objects_to_datetime64ns(\n",
    "    491     arg,\n",
    "    492     dayfirst=dayfirst,\n",
    "   (...)\n",
    "    496     allow_object=True,\n",
    "    497 )\n",
    "    499 if tz_parsed is not None:\n",
    "    500     # We can take a shortcut since the datetime64 numpy array\n",
    "    501     # is in UTC\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519, in _array_strptime_with_fallback(arg, name, utc, fmt, exact, errors)\n",
    "    508 def _array_strptime_with_fallback(\n",
    "    509     arg,\n",
    "    510     name,\n",
    "   (...)\n",
    "    514     errors: str,\n",
    "    515 ) -> Index:\n",
    "    516     \"\"\"\n",
    "    517     Call array_strptime, with fallback behavior depending on 'errors'.\n",
    "    518     \"\"\"\n",
    "--> 519     result, timezones = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n",
    "    520     if any(tz is not None for tz in timezones):\n",
    "    521         return _return_parsed_timezone_results(result, timezones, utc, name)\n",
    "\n",
    "File strptime.pyx:534, in pandas._libs.tslibs.strptime.array_strptime()\n",
    "\n",
    "File strptime.pyx:355, in pandas._libs.tslibs.strptime.array_strptime()\n",
    "\n",
    "ValueError: time data \"2/18/11\" doesn't match format \"%y-%m-%d\", at position 0. You might want to try:\n",
    "    - passing `format` if your strings have a consistent format;\n",
    "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
    "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc16aa4-4dcb-405c-8c22-3204e902eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "mktg_df= pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#clean columns names: lowercase, delete 0 in unnamed, employment status  space, change spaces for_, empty column?, \n",
    "# duplicates, nulls, formatting string and numbers and dates (map, apply)\n",
    "#with function (function that put column names in lowercase, replaces whithe espaces by _ and change  st to state\n",
    "\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    df = df.rename(columns={str('employmentstatus'): 'employment_status'})\n",
    "    df = df.rename(columns={str('unnamed:_0'): 'unnamed'})\n",
    "    return df    \n",
    "    \n",
    "    #return df\n",
    "\n",
    "mktg_df= clean_column_names(mktg_df)\n",
    "mktg_df.head()\n",
    "\n",
    "The marketing team wants to analyze the effect of different marketing channels on the customer response rate.\n",
    "Hint: You can use melt to unpivot the data and create a table that shows the customer response rate (those who responded \"Yes\") by marketing channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f199678e-6bc1-41ef-ad93-55e5b9adda08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1263102901.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    ---------------------------------------------------------------------------\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "response_rate= pd.melt(mktg_df, id_vars=['response'], value_vars=['sales_channel'], value_name='sales_channel')\n",
    "response_rate = response_rate[response_rate['response'] == 'Yes']\n",
    "response_rate = response_rate.groupby('sales_channel').size().reset_index(name='response_count')\n",
    "\n",
    "print(response_rate_by_channel)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[175], line 1\n",
    "----> 1 response_rate= pd.melt(mktg_df, id_vars=['response'], value_vars=['sales_channel'], value_name='sales_channel')\n",
    "      2 response_rate = response_rate[response_rate['response'] == 'Yes']\n",
    "      3 response_rate = response_rate.groupby('sales_channel').size().reset_index(name='response_count')\n",
    "\n",
    "File /opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/melt.py:52, in melt(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\n",
    "     49     cols = list(frame.columns)\n",
    "     51 if value_name in frame.columns:\n",
    "---> 52     raise ValueError(\n",
    "     53         f\"value_name ({value_name}) cannot match an element in \"\n",
    "     54         \"the DataFrame columns.\"\n",
    "     55     )\n",
    "     57 if id_vars is not None:\n",
    "     58     if not is_list_like(id_vars):\n",
    "\n",
    "ValueError: value_name (sales_channel) cannot match an element in the DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef5ee4-ddce-456d-b7ca-cd77d369f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
